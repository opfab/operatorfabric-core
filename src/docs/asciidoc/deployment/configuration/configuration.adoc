// Copyright (c) 2018-2023 RTE (http://www.rte-france.com)
// See AUTHORS.txt
// This document is subject to the terms of the Creative Commons Attribution 4.0 International license.
// If a copy of the license was not distributed with this
// file, You can obtain one at https://creativecommons.org/licenses/by/4.0/.
// SPDX-License-Identifier: CC-BY-4.0




:springboot_doc: https://docs.spring.io/spring-boot/docs/current/reference/htmlsingle/
:mongo_doc: https://docs.mongodb.com/manual/reference/
:spring_kafka_doc: https://docs.spring.io/spring-kafka/reference/html/

= Configuration

The configuration is divided into two parts, the configuration of the business services and the configuration of the UI. 

Opfab comes with a default embedded configuration, but certain parameters need to be provided and configured.

The configuration is centralized in the *config* directory of the GitHub repository. The dev subdirectory contains confi
gurations specific to development environments, while the *docker* subdirectory contains a specific configuration meant for use in a full docker environment.

== Business service configuration


=== Shared service configuration

The configuration shared by all services is in a yaml file, you can find an example with the file
/config/docker/common.yml.

==== Mongo configuration

We only use URI configuration for mongo through the usage of the ```spring.data.mongodb.uris```,
it allows us to share the same configuration behavior for simple or cluster
configuration and with both spring classic and reactive mongo configuration.
See link:{mongo_doc}connection-string/[mongo connection string] for the complete URI syntax.

This configuration is mandatory (no default configuration is provided).

==== Optional configuration values 

|===
|name|default|Description


|operatorfabric.servicesUrls.users|users:2103|Indicates where the Users service can be reached from the other services.
|operatorfabric.servicesUrls.businessconfig|businessconfig:2100|Indicates where the Business service can be reached from the other services.
|operatorfabric.userActionLogActivated|yes|Indicates whether the user action log feature is enabled or not.
|===

=== Service specific configurations

Each service can have a specific yaml configuration file that can override the default configuration

Examples of configuration of each service can be found under config/docker or config/dev . 

==== Businessconfig service

The businessconfig service has this specific property : 

|===
|name|default|Description

|operatorfabric.businessconfig.storage.path|/businessconfig-storage|File path to data storage folder

|===


==== Users service

The user service has these specific properties :

|===
|name|default|Description

|operatorfabric.users.default.users|null| Array of user objects to create upon startup if they don't exist
|operatorfabric.users.default.user-settings|null| Array of user settings objects to create upon startup if they don't exist
|operatorfabric.users.default.groups|null| Array of group objects to create upon startup if they don't exist
|operatorfabric.users.default.entities|null| Array of entity objects to create upon startup if they don't exist
|daysBeforeLogExpiration|61| Duration beyond which user action logs get automatically deleted

|===

[[cards-pub-conf]]
==== Cards-publication service

The cards publication service has these specific properties :

|===
|name|default|Description

|checkAuthenticationForCardSending|true|If false, OperatorFabric will not require user authentication to send or delete a card via endpoint /cards (it does not concern user cards which always need authentication). Be careful when setting the value to false, nginx conf must be adapted for security reasons (see security warning in link:https://github.com/opfab/operatorfabric-core/blob/master/config/docker/nginx.conf[the reference nginx.conf])
|authorizeToSendCardWithInvalidProcessState|false|If true, OperatorFabric will allow to publish a card referring a not existent process or state 
|checkPerimeterForCardSending|true|If true, OperatorFabric will check user perimeter for card sending via endpoint /cards (it does not concern user cards which are always controlled).
|spring.kafka.consumer.group-id |null| If set, support for receiving cards via Kafka is enabled
|spring.deserializer.value.delegate.class|io.confluent.kafka.serializers.
KafkaAvroDeserializer| Deserializer used to convert the received bytes into objects
|spring.serializer.value.delegate.class |io.confluent.kafka.serializers.
KafkaAvroSerializer|Serializer used to convert cards to bytes
|spring.kafka.producer.bootstrap-servers|http://localhost:9092|comma separated list of URL(s) of the broker(s) / bootstrap server(s)
|opfab.kafka.topics.card.topicname |opfab|Name of the topic to read the messages from
|opfab.kafka.topics.response-card.topicname |opfab|Name of the topic to place the response cards to
|opfab.kafka.schema.registry.url|http://localhost:8081|URL of the schema registry. Can be set to the empty string "" is no registry is used
|delayForDeleteExpiredCardsScheduling|60000|The delay in millisecond after the last execution finished and the next execution starts.
|===


===== OperatorFabric Kafka configuration

Next to publishing cards to OperatorFabric using the REST API, OperatorFabric also supports publishing cards via a Kafka Topic. In the default configuration Kafka is disabled.
To enable Kafka you need to set the consumer group to the consumer group you assign to the OpFab Kafka consumer. This can be any group-id, as long as it isn't used by other consumers
(unless you explicitly want multiple consumers for the same group).

You can set the group_id by uncommenting the `kafka.consumer.group_id` in the `cards-publication.yml`

[source, yaml]
----
  kafka:
    consumer:
      group-id: opfab-command
----
By default, the consumer will consume messages from the `opfab` topic.
See link:{spring_kafka_doc}[Spring for Apache Kafka] for more information on the Spring Kafka implementation.

With the default settings, the Kafka consumer expects a broker running on http//127.0.0.1:9092 and a schema registry on http://127.0.0.1:8081.

Operator Fabric is also able to publish response cards to a Kafka topic. The default topic name  `opfab-response`. You can specify which response cards
are to be returned via Kafka by setting the `external-recipients` in the `cards-publication` yaml file. Instead of setting `http://` URL you should set it to `kafka:`

[source, yaml]
----
external-recipients:
  recipients: 
    - id: "processAction"
      url: "http://localhost:8090/test"
      propagateUserToken: true
    - id: "mykafka"
      url: "kafka:topicname"
      propagateUserToken: false

----

Note that `topicname` is a placeholder for now. All response cards are returned via the same Kafka response topic, as specified in the `opfab.kafka.topics.response-card` field.

Also note enabling Kafka does not disable the REST interface.

Example Kafka configuration plain:
[source, yaml]
----
spring:
  application:
    name: cards-publication
  deserializer:
    value:
      delegate:
        class: org.opfab.cards.publication.kafka.consumer.KafkaAvroWithoutRegistryDeserializer
  serializer:
    value:
      delegate:
        class: org.opfab.cards.publication.kafka.producer.KafkaAvroWithoutRegistrySerializer
  kafka:
    consumer:
      group-id: OPFAB
      properties:
        specific:
          avro:
            reader: true
    producer:
      client-id: operatorfabric-producer
    bootstrap-servers: kafka-server:9092
opfab:
  kafka:
    topics:
      card:
        topicname: m_opfab-card-commands_dev
      response-card:
        topicname: m_opfab-card-response_dev
----

Example Kafka configuration SASL:
[source, yaml]
----
spring:
  application:
    name: cards-publication
  deserializer:
    value:
      delegate:
        class: org.opfab.cards.publication.kafka.consumer.KafkaAvroWithoutRegistryDeserializer
  serializer:
    value:
      delegate:
        class: org.opfab.cards.publication.kafka.producer.KafkaAvroWithoutRegistrySerializer
  kafka:
    consumer:
      group-id: OPFAB
      security:
        protocol: SASL_SSL
      properties:
        specific:
          avro:
            reader: true
        sasl:
          mechanism: SCRAM-SHA-256
          jaas:
            config: org.apache.kafka.common.security.scram.ScramLoginModule required username="kafkaUsername" password="kafkaPassword";
    producer:
      client-id: operatorfabric-producer
      security:
        protocol: SASL_SSL
      properties:
        sasl:
          mechanism: SCRAM-SHA-256
          jaas:
            config: org.apache.kafka.common.security.scram.ScramLoginModule required username="kafkaUsername" password="kafkaPassword";
    bootstrap-servers: kafka-server:9094
    ssl:
      trust-store-type: PKCS12
      trust-store-password: truststorePassword
      trust-store-location: file:///etc/truststore.pkcs
    properties:
      ssl:
        endpoint:
          identification:
            algorithm: ""
opfab:
  kafka:
    topics:
      card:
        topicname: opfab-card-commands
      response-card:
        topicname: opfab-card-response
----

Example Kafka configuration Kerberos:
[source, yaml]
----
spring:
  application:
    name: cards-publication
  deserializer:
    key:
      delegate:
        class: org.apache.kafka.common.serialization.StringDeserializer
    value:
      delegate:
        class: org.opfab.cards.publication.kafka.consumer.KafkaAvroWithoutRegistryDeserializer
  serializer:
    value:
      delegate:
        class: org.opfab.cards.publication.kafka.producer.KafkaAvroWithoutRegistrySerializer
  kafka:
    security:
      protocol: SASL_SSL
    properties:
      sasl.mechanism: GSSAPI
      sasl:
        jaas:
          config: com.sun.security.auth.module.Krb5LoginModule required useKeyTab=true keyTab="/etc/kafkaUsername.keytab" storeKey=true useTicketCache=false serviceName="kafka" principal="kafkaUsername@DOMAIN";
    bootstrap-servers: kafka-server:9094
    ssl:
      trust-store-type: pkcs12
      trust-store-password: truststorePassword
      trust-store-location: file:///etc/truststore.pkcs12
    consumer:
      group-id: OPFAB
      key-deserializer: org.springframework.kafka.support.serializer.ErrorHandlingDeserializer
      value-deserializer: org.springframework.kafka.support.serializer.ErrorHandlingDeserializer
      properties:
        spring:
          deserializer:
            key:
              delegate:
                class: org.apache.kafka.common.serialization.StringDeserializer
            value:
              delegate:
                class: org.opfab.cards.publication.kafka.consumer.KafkaAvroWithoutRegistryDeserializer
    producer:
      client-id: OPFAB
      value-serializer: org.opfab.cards.publication.kafka.producer.KafkaAvroWithoutRegistrySerializer
opfab:
  kafka:
    topics:
      card:
        topicname: opfab-card-commands
      response-card:
        topicname: opfab-card-response
----

Example Kafka configuration OAUTHBEARER / AADToken:
[source, yaml]
----
spring:
  kafka:
    consumer:
      properties:
        "[security.protocol]": SASL_SSL
        "[sasl.jaas.config]": org.apache.kafka.common.security.oauthbearer.OAuthBearerLoginModule required ;
        "[sasl.mechanism]": OAUTHBEARER
        "[sasl.login.callback.handler.class]": org.opfab.cards.publication.kafka.auth.AADWorkloadIdentityLoginCallbackHandler
    producer:
      ...the same...
----


==== Cards-consultation service

The cards-consultation service has these specific properties :

|===
|name|default|Description

|checkIfUserIsAlreadyConnected|true|If false, OperatorFabric will allow a user to have several sessions opened at the same time. However, it may cause synchronization problems between the sessions using the same login, so it is recommended to let it true, its default value. 
|operatorfabric.heartbeat.checkIntervalInSeconds|10| Frequency at which the heartbeat from the ui to the server is checked.
|operatorfabric.heartbeat.delayInSecondsToConsiderUserDisconnected|100| After how many seconds without heartbeat, the user is considered disconnected
|===

[[external-devices-conf]]
==== External devices service

The external devices service can be configured with the following properties:

|===
|name|default|Description

|operatorfabric.externaldevices.watchdog.enabled|false|If true, watchdog signals will be sent to external devices to show that the OperatorFabric is running and connected.
|operatorfabric.externaldevices.watchdog.cron|`*/5 * * * * *`|CRON expression determining when watchdog signals should be sent to external devices.
|operatorfabric.externaldevices.watchdog.signalId|0|Id of the signal the external devices are expecting as watchdog
|===

==== Node services configuration

The configuration of node services (cards-external-diffusion and cards-reminder) is located in config/docker folder.
The 'node-services.json' configuration file contains parameters common to all the node services and a dedicated section for each service.
Node services can be configured with the following properties:

|===
|name|default|mandatory?|Description
|opfab.url||yes| Opfab URL
|opfab.connectedUsersUrl||yes|Service URL to get the list of users currently connected to Opfab
|opfab.cardsUrl||yes|Cards consultation service URL
|opfab.usersUrl||yes|Users service URL
|opfab.cardReminderUrl||yes| Opfab card resetReadAndAcks endpoint URL
|opfab.getTokenUrl||yes|Authentication service URL
|opfab.tokenExpireClaim||yes|Token expiration property
|rabbitmq.host||yes|RabbitMQ host address
|rabbitmq.port||yes|RabbitMQ listen port
|rabbitmq.username||yes|RabbitMQ username
|rabbitmq.password||yes|RabbitMQ password
|logConfig.logFolder||yes|Log file folder
|logConfig.logFile||yes|Log file name
|logConfig.logLevel||yes|Default log level
|mail.host||yes|Mail server host
|mail.port||yes|Mail server port
|mail.auth.user||yes|Mail server authentication user
|mail.auth.pass||yes|Mail server authentication password
|mongodb.database||yes|MongoDB database name
|mongodb.uri||yes|MongoDB connection URI
|cardsExternalDiffusion.adminPort||yes|Listen port
|cardsExternalDiffusion.activeOnStartup||yes|Flag to start the notification service on startup
|cardsExternalDiffusion.opfab.login||yes|user account used to call Opfab services
|cardsExternalDiffusion.opfab.password||yes|user password to call Opfab services
|cardsExternalDiffusion.defaultConfig.mailFrom||yes|Mail from address
|cardsExternalDiffusion.defaultConfig.subjectPrefix||yes|Mail subject prefix
|cardsExternalDiffusion.defaultConfig.bodyPrefix|||Mail body prefix
|cardsExternalDiffusion.defaultConfig.windowInSecondsForCardSearch|||Max time interval used to query new cards (in seconds)
|cardsExternalDiffusion.defaultConfig.secondsAfterPublicationToConsiderCardAsNotRead|||Time period after card publication before sending mail notification
|cardsExternalDiffusion.defaultConfig.checkPeriodInSeconds|||Time interval between consecutive checks
|cardsReminder.adminPort||yes|Cards reminder service Listen port
|cardsReminder.activeOnStartup||yes|Flag to start the cards reminder service on startup
|cardsReminder.checkPeriodInSeconds|||Cards reminder time interval between consecutive checks
|===

The parameters in "cardsExternalDiffusion.defaultConfig" section of cards external diffusion can be modified at runtime by sending an http POST request to the `/config` API with a JSON payload containing the config parameters to be changed.



include::web-ui_configuration.adoc[leveloffset=+1]



[[opfab_spec_conf]]
include::security_configuration.adoc[leveloffset=+1]